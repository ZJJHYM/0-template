# @package _global_
batch_size: 32
model: co_attn_trans_pooling
co_attention_head: 8
co_attention_layer: 6
d_model: 768
hidden_dim: 1024
pooling_head: 8
pooling_dim: 512
pooling_layer: 6
dropout: 0.3

lr_scheduler: null

modal_list:
  - video
  - audio
  - text

trainer:
  gpus:
    - 0
  val_check_interval: 50